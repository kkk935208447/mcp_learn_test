{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5870d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from openai.resources.chat.completions.completions import NOT_GIVEN\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from loguru import logger\n",
    "from typing import Any, List, Dict, Optional\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023ddef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env if present\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "BASE_URL = os.getenv(\"OPENAI_BASE_URL\")\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "if (not API_KEY) or (not BASE_URL):\n",
    "    raise RuntimeError(\"OPENAI_API_KEY or OPENAI_BASE_URL environment variable not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24369e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"计算两个实数的和\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"获取某地区的天气\"\"\"\n",
    "    return f\"{location}：晴，温度25℃\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveLLMClient:\n",
    "    \"\"\"支持递归多轮function call的 OpenAI 客户端，function call 具体的【多轮】调用步骤见：https://platform.openai.com/docs/guides/function-calling?api-mode=chat\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.openai_client = OpenAI(\n",
    "            base_url=BASE_URL,\n",
    "            api_key=API_KEY\n",
    "        )\n",
    "        self.model = MODEL\n",
    "        logger.info(f\"{self.__class__.__name__} initialized, params: {self.__dict__}\")\n",
    "\n",
    "    @property\n",
    "    def get_client(self):\n",
    "        return self.openai_client\n",
    "\n",
    "    @property\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def get_chat_completions_response(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = NOT_GIVEN) -> ChatCompletion:\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\" if tools else NOT_GIVEN\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def call_local_tool(self, function_name: str, function_args: dict):\n",
    "        \"\"\"执行本地函数\"\"\"\n",
    "        # globals() 是一个内置函数，它返回一个字典，表示当前全局符号表。这个字典包含了当前模块中定义的所有名称和它们所对应的对象。\n",
    "        if function_name not in globals():\n",
    "            logger.error(f\"Function {function_name} is not implemented in globals.\")\n",
    "            raise RuntimeError(f\"Function {function_name} is not implemented in globals.\")\n",
    "        return globals()[function_name](**function_args)\n",
    "\n",
    "    def recursive_chat(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = NOT_GIVEN):\n",
    "        \"\"\"\n",
    "        支持递归处理多轮function call，直到LLM回复content（没有tool_call为止）。\n",
    "        每当检测到tool_call，则自动本地执行并将结果追加回到messages，再次调用LLM。\n",
    "        返回最终assistant文本及消息列表。\n",
    "        \"\"\"\n",
    "\n",
    "        iter_n = 0\n",
    "        while True:\n",
    "            response = self.get_chat_completions_response(messages=messages, tools=tools)\n",
    "            choice = response.choices[0]\n",
    "            finish_reason = choice.finish_reason\n",
    "\n",
    "            iter_n += 1  # 增加迭代轮数\n",
    "            if iter_n > 5:\n",
    "                logger.error(f\"迭代次数超过5次，疑似出现死循环，终止递归。\")\n",
    "                return None, messages\n",
    "\n",
    "            if finish_reason == \"tool_calls\":\n",
    "                tool_calls = choice.message.tool_calls or []\n",
    "                logger.info(f\"递归次数{iter_n}，检测到tool_calls, 共{len(tool_calls)}个，将递归执行：{[i.function.name for i in tool_calls]}\")\n",
    "\n",
    "                # 将（本次）LLM的tool_call(messsage)也追加，function call 具体的【多轮】调用步骤见：https://platform.openai.com/docs/guides/function-calling?api-mode=chat\n",
    "                _message = choice.message.model_dump()\n",
    "                _message[\"content\"] = None   # content 内容重置为None，有些类似qwen3的推理模型content不为空，重置为None\n",
    "                messages.append(_message)\n",
    "\n",
    "                # 按顺序执行全部tool_calls并记录内容\n",
    "                for tool_call in tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    try:\n",
    "                        function_args = json.loads(tool_call.function.arguments)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"解析function arguments失败: {tool_call.function.arguments}, err: {e}\")\n",
    "                        function_args = {}\n",
    "                    logger.info(f\"调用本地函数: {function_name}, 参数: {function_args}\")\n",
    "                    function_response = self.call_local_tool(function_name, function_args)\n",
    "                    logger.info(f\"函数结果: {function_response}\")\n",
    "\n",
    "                    # tool role 的标准格式\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": str(function_response)\n",
    "                    })\n",
    "\n",
    "                # 继续下一轮带结果递归\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                assistant_text = choice.message.content\n",
    "                # 将最终回复加入历史\n",
    "                messages.append({\"role\": \"assistant\", \"content\": assistant_text})\n",
    "                # logger.info(f\"递归结束，生成assistant回复: {assistant_text}\")\n",
    "                return assistant_text, messages\n",
    "            \n",
    "\n",
    "    \n",
    "    def recursive_chatV2(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = NOT_GIVEN):\n",
    "        \"\"\"\n",
    "        相对于上面的函数，这个版本会使用 role 为 `fuction` 的 message 来记录函数调用的结果，而不是使用 `tool` 的 message 来记录。\n",
    "        # NOTE：实际测试下来，role 为 tool 比 role 为 function 更稳定，但是 role 为 function 更简洁。\n",
    "        \"\"\"\n",
    "\n",
    "        iter_n = 0\n",
    "        while True:\n",
    "            # 打印当前的messages\n",
    "            logger.info(f\"当前轮的messages: \\n{messages}\")\n",
    "\n",
    "            response = self.get_chat_completions_response(messages=messages, tools=tools)\n",
    "            choice = response.choices[0]\n",
    "            finish_reason = choice.finish_reason\n",
    "\n",
    "            iter_n += 1  # 增加迭代轮数\n",
    "            if iter_n > 5:\n",
    "                logger.error(f\"迭代次数超过5次，疑似出现死循环，终止递归。\")\n",
    "                return None, messages\n",
    "\n",
    "            if finish_reason == \"tool_calls\":\n",
    "                tool_calls = choice.message.tool_calls or []\n",
    "                logger.info(f\"递归次数{iter_n}，检测到tool_calls, 共{len(tool_calls)}个，将递归执行：{[i.function.name for i in tool_calls]}\")\n",
    "\n",
    "                # 按顺序执行全部tool_calls并记录内容\n",
    "                for tool_call in tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    try:\n",
    "                        function_args = json.loads(tool_call.function.arguments)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"解析function arguments失败: {tool_call.function.arguments}, err: {e}\")\n",
    "                        function_args = {}\n",
    "                    logger.info(f\"调用本地函数: {function_name}, 参数: {function_args}\")\n",
    "                    function_response = self.call_local_tool(function_name, function_args)\n",
    "                    logger.info(f\"函数结果: {function_response}\")\n",
    "\n",
    "                    # role 使用function的格式\n",
    "                    messages.append({\n",
    "                        \"role\": \"function\",\n",
    "                        \"name\": f\"{function_name}\",\n",
    "                        \"content\": f\"{str(function_response)}\"\n",
    "                    })\n",
    "\n",
    "                # 继续下一轮带结果递归\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                assistant_text = choice.message.content\n",
    "                # 将最终回复加入历史\n",
    "                messages.append({\"role\": \"assistant\", \"content\": assistant_text})\n",
    "                # logger.info(f\"递归结束，生成assistant回复: {assistant_text}\")\n",
    "                return assistant_text, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7feeaca",
   "metadata": {},
   "source": [
    "#### 测试function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21abdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-05 18:28:01.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mRecursiveLLMClient initialized, params: {'openai_client': <openai.OpenAI object at 0x7ff3c19ff450>, 'model': 'qwen3:8b'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用模型: qwen3:8b\n",
      "\n",
      "开始多轮递归对话（输入exit退出）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-05 18:28:03.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1m当前轮的messages: \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '你是一个AI助手，你可以使用工具来获取信息。然后你可以根据这些信息来回答用户的问题。', 'role': 'system'},\n",
      " {'content': '你好', 'role': 'user'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-05 18:28:05.368\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m67\u001b[0m - \u001b[32m\u001b[1mAssistant:\n",
      "<think>\n",
      "好的，用户打招呼说“你好”，我需要回应。作为AI助手，我应该友好回应，并询问如何帮助用户。查看可用工具，有add和get_weather，但用户还没提到具体问题。所以先不用调用工具，直接回复即可。保持自然，不用任何工具调用。\n",
      "</think>\n",
      "\n",
      "你好！有什么我可以帮助你的吗？\u001b[0m\n",
      "\u001b[32m2025-06-05 18:28:14.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1m当前轮的messages: \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '你是一个AI助手，你可以使用工具来获取信息。然后你可以根据这些信息来回答用户的问题。', 'role': 'system'},\n",
      " {'content': '你好', 'role': 'user'},\n",
      " {'content': '<think>\\n'\n",
      "             '好的，用户打招呼说“你好”，我需要回应。作为AI助手，我应该友好回应，并询问如何帮助用户。查看可用工具，有add和get_weather，但用户还没提到具体问题。所以先不用调用工具，直接回复即可。保持自然，不用任何工具调用。\\n'\n",
      "             '</think>\\n'\n",
      "             '\\n'\n",
      "             '你好！有什么我可以帮助你的吗？',\n",
      "  'role': 'assistant'},\n",
      " {'content': '', 'role': 'user'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-05 18:28:17.292\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m67\u001b[0m - \u001b[32m\u001b[1mAssistant:\n",
      "<think>\n",
      "好的，用户刚才发来一个空消息，我需要弄清楚他们想要什么。之前用户只是打了个招呼，现在可能是在测试或者想继续对话。我应该保持友好，鼓励他们提出问题或请求帮助。可能用户没有想好要问什么，所以用开放式的提问引导他们。比如询问是否需要帮助，或者有没有具体的问题。同时要保持简洁，不要让用户感到压力。确保回应亲切，方便用户表达需求。\n",
      "</think>\n",
      "\n",
      "你好！有什么我可以帮助你的吗？\u001b[0m\n",
      "\u001b[32m2025-06-05 18:28:28.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1m当前轮的messages: \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '你是一个AI助手，你可以使用工具来获取信息。然后你可以根据这些信息来回答用户的问题。', 'role': 'system'},\n",
      " {'content': '你好', 'role': 'user'},\n",
      " {'content': '<think>\\n'\n",
      "             '好的，用户打招呼说“你好”，我需要回应。作为AI助手，我应该友好回应，并询问如何帮助用户。查看可用工具，有add和get_weather，但用户还没提到具体问题。所以先不用调用工具，直接回复即可。保持自然，不用任何工具调用。\\n'\n",
      "             '</think>\\n'\n",
      "             '\\n'\n",
      "             '你好！有什么我可以帮助你的吗？',\n",
      "  'role': 'assistant'},\n",
      " {'content': '', 'role': 'user'},\n",
      " {'content': '<think>\\n'\n",
      "             '好的，用户刚才发来一个空消息，我需要弄清楚他们想要什么。之前用户只是打了个招呼，现在可能是在测试或者想继续对话。我应该保持友好，鼓励他们提出问题或请求帮助。可能用户没有想好要问什么，所以用开放式的提问引导他们。比如询问是否需要帮助，或者有没有具体的问题。同时要保持简洁，不要让用户感到压力。确保回应亲切，方便用户表达需求。\\n'\n",
      "             '</think>\\n'\n",
      "             '\\n'\n",
      "             '你好！有什么我可以帮助你的吗？',\n",
      "  'role': 'assistant'},\n",
      " {'content': '帮我查看一下上海南京南宁长沙东京武汉焦作兰  考开封沈阳的温度， 计算一下839839+89389.38 与 '\n",
      "             '893839+89893.389的值，获得纽约的天气',\n",
      "  'role': 'user'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-05 18:29:02.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1m轮次1，检测到tool_calls, 共13个，将递归执行：['get_weather', 'get_weather', 'get_weather', 'get_weather', 'get_weather', 'get_weather', 'get_weather', 'get_weather', 'get_weather', 'get_weather', 'get_weather', 'add', 'add']\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '上海'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 上海：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '南京'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 南京：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '南宁'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 南宁：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '长沙'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 长沙：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '东京'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 东京：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '武汉'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 武汉：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '焦作'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 焦作：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '兰考'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 兰考：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '开封'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 开封：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '沈阳'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 沈阳：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: get_weather, 参数: {'location': '纽约'}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 纽约：晴，温度25℃\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: add, 参数: {'a': 839839, 'b': 89389.38}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 929228.38\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1m调用本地函数: add, 参数: {'a': 893839, 'b': 89893.389}\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:02.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrecursive_chat\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1m函数结果: 983732.389\u001b[0m\n",
      "\u001b[32m2025-06-05 18:29:14.352\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m67\u001b[0m - \u001b[32m\u001b[1mAssistant:\n",
      "<think>\n",
      "好的，现在我要处理用户的所有请求。首先，用户让我查看多个城市的温度，包括上海、南京、南宁、长沙、东京、武汉、焦作、兰考、开封、沈阳和纽约。然后需要计算两个数值的和：839839加89389.38，以及893839加89893.389。最后，用户还提到要获得纽约的天气。\n",
      "\n",
      "首先，我需要确认用户是否希望获取所有列出城市的天气，还是只有纽约的。但根据用户给出的工具，get_weather函数可以查询任何地点的天气。所以我要为每个城市调用get_weather函数。不过用户可能希望所有城市都查询，但工具调用可能需要逐一处理，但根据之前助手的回复，用户可能希望所有城市都获取天气信息，所以应该调用每个城市的get_weather。\n",
      "\n",
      "接下来是计算两个加法。用户给出的两个表达式分别是839839 + 89389.38和893839 + 89893.389。这里需要注意的是，数值的大小和小数位数。第一个计算是839839加上89389.38，结果应该是929228.38。第二个是893839加上89893.389，结果是983732.389。需要确认数值是否正确，避免计算错误。\n",
      "\n",
      "然后是关于纽约的天气，虽然用户已经在列表中提到了纽约，但可能需要单独确认，不过根据之前的工具调用，已经包含在内。\n",
      "\n",
      "现在检查用户的回复是否正确。根据工具调用的结果，所有城市的温度都是25℃，晴，这可能不太现实，但可能是测试数据。用户可能希望得到这些结果的汇总，包括每个城市的天气、计算结果以及纽约的天气。因此，在最终回答中需要整合这些信息，确保每个部分都正确，并且数值计算准确无误。\n",
      "\n",
      "同时，用户可能希望回答简洁明了，分点列出每个城市的天气情况，然后给出计算结果，最后提到纽约的天气。需要注意不要遗漏任何请求的内容，并且确保数值计算正确。\n",
      "</think>\n",
      "\n",
      "以下是您查询的信息汇总：\n",
      "\n",
      "一、温度情况（部分城市可能受数据源限制显示相同值）：\n",
      "上海：晴，25℃\n",
      "南京：晴，25℃\n",
      "南宁：晴，25℃\n",
      "长沙：晴，25℃\n",
      "东京：晴，25℃\n",
      "武汉：晴，25℃\n",
      "焦作：晴，25℃\n",
      "兰考：晴，25℃\n",
      "开封：晴，25℃\n",
      "沈阳：晴，25℃\n",
      "纽约：晴，25℃\n",
      "\n",
      "二、数值计算：\n",
      "1. 839839 + 89389.38 = 929228.38\n",
      "2. 893839 + 89893.389 = 983732.389\n",
      "\n",
      "注：实际天气数据可能因数据源差异出现相同温度值，建议通过专业气象平台获取实时数据。\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m开始多轮递归对话（输入exit退出）\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     user_input = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUser: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m user_input.lower() == \u001b[33m\"\u001b[39m\u001b[33mexit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/document/Agents/mcp_learnning_test/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1280\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/document/Agents/mcp_learnning_test/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1323\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1324\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1327\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 示例函数工具定义（可自行扩充）\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add\",\n",
    "            \"description\": \"计算两个实数的和\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"a\": {\"type\": \"number\", \"description\": \"第一个实数\"},\n",
    "                    \"b\": {\"type\": \"number\", \"description\": \"第二个实数\"}\n",
    "                },\n",
    "                \"required\": [\"a\", \"b\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"获取某地区的天气\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"待查询的地区\"}\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# 演示loop，与LLM对话\n",
    "client = RecursiveLLMClient()\n",
    "print(f\"使用模型: {client.get_model}\\n\")\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"你是一个AI助手，你可以使用工具来获取信息。然后你可以根据这些信息来回答用户的问题。\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "print(\"开始多轮递归对话（输入exit退出）\")\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    logger.info(f\"当前轮的messages: \\n\")\n",
    "    pprint(messages)\n",
    "\n",
    "    # 对话\n",
    "    assistant_text, messages = client.recursive_chat(messages=messages, tools=tools)\n",
    "    # assistant_text, messages = client.recursive_chatV2(messages=messages, tools=tools)\n",
    "\n",
    "    logger.success(f\"Assistant:\\n{assistant_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
